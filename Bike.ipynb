{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import cv2\\nimport numpy as np\\nimport tkinter as tk\\nfrom tkinter import ttk\\nfrom PIL import Image, ImageTk\\nfrom keras.models import load_model\\n\\nclass HelmetDetectionApp:\\n    def __init__(self, root, video_source):\\n        self.root = root\\n        self.root.title(\"Helmet Detection App\")\\n\\n        self.video_source = video_source\\n        self.cap = cv2.VideoCapture(self.video_source)\\n\\n        self.width = int(self.cap.get(3))\\n        self.height = int(self.cap.get(4))\\n\\n        self.create_widgets()\\n\\n        self.update()\\n\\n    def create_widgets(self):\\n        self.label = ttk.Label(self.root, text=\"Helmet Detection\")\\n        self.label.pack(padx=10, pady=10)\\n\\n        self.canvas = tk.Canvas(self.root, width=self.width, height=self.height)\\n        self.canvas.pack()\\n\\n        self.quit_button = ttk.Button(self.root, text=\"Quit\", command=self.quit)\\n        self.quit_button.pack(pady=10)\\n\\n        # Load YOLOv3\\n        self.net = cv2.dnn.readNet(\"yolov3-custom.cfg\", \"yolov3-custom_7000.weights\")\\n\\n        # Load helmet-nonhelmet model\\n        self.helmet_model = load_model(\"helmet-nonhelmet_cnn.h5\")\\n\\n    def update(self):\\n        ret, frame = self.cap.read()\\n\\n        if ret:\\n            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\\n\\n            # YOLOv3 detection\\n            blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\\n            self.net.setInput(blob)\\n            outs = self.net.forward(self.net.getUnconnectedOutLayersNames())\\n\\n            for out in outs:\\n                for detection in out:\\n                    scores = detection[5:]\\n                    class_id = np.argmax(scores)\\n                    confidence = scores[class_id]\\n                    if confidence > 0.5 and class_id == 0:  # Class ID for helmet (adjust if needed)\\n                        center_x = int(detection[0] * self.width)\\n                        center_y = int(detection[1] * self.height)\\n                        w = int(detection[2] * self.width)\\n                        h = int(detection[3] * self.height)\\n\\n                        x = int(center_x - w / 2)\\n                        y = int(center_y - h / 2)\\n\\n                        # Extract helmet region from the frame\\n                        helmet_roi = frame[y:y + h, x:x + w]\\n\\n                        # Preprocess helmet_roi for helmet-nonhelmet model\\n                        helmet_roi_resized = cv2.resize(helmet_roi, (224, 224))  # Resize to match model input shape\\n                        helmet_roi_normalized = helmet_roi_resized / 255.0\\n                        helmet_roi_final = np.expand_dims(helmet_roi_normalized, axis=0)\\n\\n                        # Predict helmet or nonhelmet\\n                        prediction = self.helmet_model.predict(helmet_roi_final)[0]\\n\\n                        # Draw bounding box and label\\n                        label = \"Helmet\" if prediction[0] > 0.5 else \"No Helmet\"\\n                        color = (0, 255, 0) if label == \"Helmet\" else (0, 0, 255)\\n                        cv2.rectangle(frame_rgb, (x, y), (x + w, y + h), color, 2)\\n                        cv2.putText(frame_rgb, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\\n\\n            self.photo = ImageTk.PhotoImage(image=Image.fromarray(frame_rgb))\\n            self.canvas.create_image(0, 0, anchor=tk.NW, image=self.photo)\\n\\n        self.root.after(10, self.update)\\n\\n    def quit(self):\\n        self.cap.release()\\n        self.root.destroy()\\n\\nif __name__ == \"__main__\":\\n    root = tk.Tk()\\n    app = HelmetDetectionApp(root, video_source=\"stock-footage-india-goa-local-indian-people-ride-motor-bike-lot-native-hindu-drive-motorcycle-india.webm\")\\n    root.mainloop()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "from keras.models import load_model\n",
    "\n",
    "class HelmetDetectionApp:\n",
    "    def __init__(self, root, video_source):\n",
    "        self.root = root\n",
    "        self.root.title(\"Helmet Detection App\")\n",
    "\n",
    "        self.video_source = video_source\n",
    "        self.cap = cv2.VideoCapture(self.video_source)\n",
    "\n",
    "        self.width = int(self.cap.get(3))\n",
    "        self.height = int(self.cap.get(4))\n",
    "\n",
    "        self.create_widgets()\n",
    "\n",
    "        self.update()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.label = ttk.Label(self.root, text=\"Helmet Detection\")\n",
    "        self.label.pack(padx=10, pady=10)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.root, width=self.width, height=self.height)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.quit_button = ttk.Button(self.root, text=\"Quit\", command=self.quit)\n",
    "        self.quit_button.pack(pady=10)\n",
    "\n",
    "        # Load YOLOv3\n",
    "        self.net = cv2.dnn.readNet(\"yolov3-custom.cfg\", \"yolov3-custom_7000.weights\")\n",
    "\n",
    "        # Load helmet-nonhelmet model\n",
    "        self.helmet_model = load_model(\"helmet-nonhelmet_cnn.h5\")\n",
    "\n",
    "    def update(self):\n",
    "        ret, frame = self.cap.read()\n",
    "\n",
    "        if ret:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # YOLOv3 detection\n",
    "            blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "            self.net.setInput(blob)\n",
    "            outs = self.net.forward(self.net.getUnconnectedOutLayersNames())\n",
    "\n",
    "            for out in outs:\n",
    "                for detection in out:\n",
    "                    scores = detection[5:]\n",
    "                    class_id = np.argmax(scores)\n",
    "                    confidence = scores[class_id]\n",
    "                    if confidence > 0.5 and class_id == 0:  # Class ID for helmet (adjust if needed)\n",
    "                        center_x = int(detection[0] * self.width)\n",
    "                        center_y = int(detection[1] * self.height)\n",
    "                        w = int(detection[2] * self.width)\n",
    "                        h = int(detection[3] * self.height)\n",
    "\n",
    "                        x = int(center_x - w / 2)\n",
    "                        y = int(center_y - h / 2)\n",
    "\n",
    "                        # Extract helmet region from the frame\n",
    "                        helmet_roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "                        # Preprocess helmet_roi for helmet-nonhelmet model\n",
    "                        helmet_roi_resized = cv2.resize(helmet_roi, (224, 224))  # Resize to match model input shape\n",
    "                        helmet_roi_normalized = helmet_roi_resized / 255.0\n",
    "                        helmet_roi_final = np.expand_dims(helmet_roi_normalized, axis=0)\n",
    "\n",
    "                        # Predict helmet or nonhelmet\n",
    "                        prediction = self.helmet_model.predict(helmet_roi_final)[0]\n",
    "\n",
    "                        # Draw bounding box and label\n",
    "                        label = \"Helmet\" if prediction[0] > 0.5 else \"No Helmet\"\n",
    "                        color = (0, 255, 0) if label == \"Helmet\" else (0, 0, 255)\n",
    "                        cv2.rectangle(frame_rgb, (x, y), (x + w, y + h), color, 2)\n",
    "                        cv2.putText(frame_rgb, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            self.photo = ImageTk.PhotoImage(image=Image.fromarray(frame_rgb))\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=self.photo)\n",
    "\n",
    "        self.root.after(10, self.update)\n",
    "\n",
    "    def quit(self):\n",
    "        self.cap.release()\n",
    "        self.root.destroy()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = HelmetDetectionApp(root, video_source=\"stock-footage-india-goa-local-indian-people-ride-motor-bike-lot-native-hindu-drive-motorcycle-india.webm\")\n",
    "    root.mainloop()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import cv2\\nimport numpy as np\\nfrom keras.models import load_model\\nimport tkinter as tk\\nfrom PIL import Image, ImageTk\\n\\nclass HelmetDetectionApp:\\n    def __init__(self, video_source):\\n        self.video_source = video_source\\n        self.cap = cv2.VideoCapture(self.video_source)\\n\\n        self.frame_width = 500\\n        self.frame_height = 500\\n\\n        # Load YOLOv3\\n        self.net = cv2.dnn.readNet(\"yolov3-custom.cfg\", \"yolov3-custom_7000.weights\")\\n\\n        # Load helmet-nonhelmet model\\n        self.helmet_model = load_model(\"helmet-nonhelmet_cnn.h5\")\\n\\n        self.root = tk.Tk()\\n        self.root.title(\"Helmet Detection\")\\n\\n        self.label = tk.Label(self.root)\\n        self.label.pack()\\n\\n        self.update()\\n\\n        self.root.mainloop()\\n\\n    def update(self):\\n        ret, frame = self.cap.read()\\n\\n        if ret:\\n            # Resize frame for speedup\\n            frame = cv2.resize(frame, (self.frame_width, self.frame_height))\\n            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\\n\\n            # YOLOv3 detection\\n            blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\\n            self.net.setInput(blob)\\n            outs = self.net.forward(self.net.getUnconnectedOutLayersNames())\\n\\n            helmet_detected = False  # Flag to check if a helmet is detected\\n\\n            for out in outs:\\n                for detection in out:\\n                    scores = detection[5:]\\n                    class_id = np.argmax(scores)\\n                    confidence = scores[class_id]\\n                    if confidence > 0.5 and class_id == 0:  # Class ID for helmet (adjust if needed)\\n                        x, y, w, h = self.get_bbox_coordinates(detection)\\n\\n                        # Check if width and height are positive\\n                        if w > 0 and h > 0:\\n                            # Extract helmet region from the frame\\n                            helmet_roi = frame[y:y + h, x:x + w]\\n\\n                            # Check if the helmet_roi is not empty\\n                            if not helmet_roi.size == 0:\\n                                # Preprocess helmet_roi for helmet-nonhelmet model\\n                                helmet_roi_resized = cv2.resize(helmet_roi, (224, 224))\\n                                helmet_roi_normalized = helmet_roi_resized / 255.0\\n                                helmet_roi_final = np.expand_dims(helmet_roi_normalized, axis=0)\\n\\n                                # Predict helmet or nonhelmet\\n                                prediction = self.helmet_model.predict(helmet_roi_final)[0]\\n\\n                                # Draw bounding box and label\\n                                label = \"Helmet\" if prediction[0] > 0.5 else \"No Helmet\"\\n                                color = (0, 255, 0) if label == \"Helmet\" else (0, 0, 255)\\n                                cv2.rectangle(frame_rgb, (x, y), (x + w, y + h), color, 2)\\n                                cv2.putText(frame_rgb, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\\n\\n                                helmet_detected = True\\n\\n            # Convert the frame to a format compatible with Tkinter\\n            image = Image.fromarray(frame_rgb)\\n            image = ImageTk.PhotoImage(image=image)\\n\\n            # Update the label with the new image\\n            self.label.config(image=image)\\n            self.label.image = image\\n\\n        # Schedule the next update after 10 milliseconds\\n        self.root.after(10, self.update)\\n\\n    def get_bbox_coordinates(self, detection):\\n        center_x, center_y, w, h = int(detection[0] * self.frame_width), int(detection[1] * self.frame_height),                                    int(detection[2] * self.frame_width), int(detection[3] * self.frame_height)\\n        x, y = int(center_x - w / 2), int(center_y - h / 2)\\n        return x, y, w, h\\n\\nif __name__ == \"__main__\":\\n    app = HelmetDetectionApp(video_source=\"stock-footage-india-goa-local-indian-people-ride-motor-bike-lot-native-hindu-drive-motorcycle-india (1).webm\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "class HelmetDetectionApp:\n",
    "    def __init__(self, video_source):\n",
    "        self.video_source = video_source\n",
    "        self.cap = cv2.VideoCapture(self.video_source)\n",
    "\n",
    "        self.frame_width = 500\n",
    "        self.frame_height = 500\n",
    "\n",
    "        # Load YOLOv3\n",
    "        self.net = cv2.dnn.readNet(\"yolov3-custom.cfg\", \"yolov3-custom_7000.weights\")\n",
    "\n",
    "        # Load helmet-nonhelmet model\n",
    "        self.helmet_model = load_model(\"helmet-nonhelmet_cnn.h5\")\n",
    "\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Helmet Detection\")\n",
    "\n",
    "        self.label = tk.Label(self.root)\n",
    "        self.label.pack()\n",
    "\n",
    "        self.update()\n",
    "\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def update(self):\n",
    "        ret, frame = self.cap.read()\n",
    "\n",
    "        if ret:\n",
    "            # Resize frame for speedup\n",
    "            frame = cv2.resize(frame, (self.frame_width, self.frame_height))\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # YOLOv3 detection\n",
    "            blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "            self.net.setInput(blob)\n",
    "            outs = self.net.forward(self.net.getUnconnectedOutLayersNames())\n",
    "\n",
    "            helmet_detected = False  # Flag to check if a helmet is detected\n",
    "\n",
    "            for out in outs:\n",
    "                for detection in out:\n",
    "                    scores = detection[5:]\n",
    "                    class_id = np.argmax(scores)\n",
    "                    confidence = scores[class_id]\n",
    "                    if confidence > 0.5 and class_id == 0:  # Class ID for helmet (adjust if needed)\n",
    "                        x, y, w, h = self.get_bbox_coordinates(detection)\n",
    "\n",
    "                        # Check if width and height are positive\n",
    "                        if w > 0 and h > 0:\n",
    "                            # Extract helmet region from the frame\n",
    "                            helmet_roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "                            # Check if the helmet_roi is not empty\n",
    "                            if not helmet_roi.size == 0:\n",
    "                                # Preprocess helmet_roi for helmet-nonhelmet model\n",
    "                                helmet_roi_resized = cv2.resize(helmet_roi, (224, 224))\n",
    "                                helmet_roi_normalized = helmet_roi_resized / 255.0\n",
    "                                helmet_roi_final = np.expand_dims(helmet_roi_normalized, axis=0)\n",
    "\n",
    "                                # Predict helmet or nonhelmet\n",
    "                                prediction = self.helmet_model.predict(helmet_roi_final)[0]\n",
    "\n",
    "                                # Draw bounding box and label\n",
    "                                label = \"Helmet\" if prediction[0] > 0.5 else \"No Helmet\"\n",
    "                                color = (0, 255, 0) if label == \"Helmet\" else (0, 0, 255)\n",
    "                                cv2.rectangle(frame_rgb, (x, y), (x + w, y + h), color, 2)\n",
    "                                cv2.putText(frame_rgb, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "                                helmet_detected = True\n",
    "\n",
    "            # Convert the frame to a format compatible with Tkinter\n",
    "            image = Image.fromarray(frame_rgb)\n",
    "            image = ImageTk.PhotoImage(image=image)\n",
    "\n",
    "            # Update the label with the new image\n",
    "            self.label.config(image=image)\n",
    "            self.label.image = image\n",
    "\n",
    "        # Schedule the next update after 10 milliseconds\n",
    "        self.root.after(10, self.update)\n",
    "\n",
    "    def get_bbox_coordinates(self, detection):\n",
    "        center_x, center_y, w, h = int(detection[0] * self.frame_width), int(detection[1] * self.frame_height), \\\n",
    "                                   int(detection[2] * self.frame_width), int(detection[3] * self.frame_height)\n",
    "        x, y = int(center_x - w / 2), int(center_y - h / 2)\n",
    "        return x, y, w, h\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = HelmetDetectionApp(video_source=\"stock-footage-india-goa-local-indian-people-ride-motor-bike-lot-native-hindu-drive-motorcycle-india (1).webm\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import cv2\\nimport numpy as np\\nfrom keras.models import load_model\\nimport tkinter as tk\\nfrom PIL import Image, ImageTk\\n\\nclass HelmetDetectionApp:\\n    def __init__(self, video_source):\\n        self.video_source = video_source\\n        self.cap = cv2.VideoCapture(self.video_source)\\n\\n        self.frame_width = 500\\n        self.frame_height = 500\\n\\n        # Load YOLOv3\\n        self.net = cv2.dnn.readNet(\"yolov3-custom.cfg\", \"yolov3-custom_7000.weights\")\\n\\n        # Load helmet-nonhelmet model\\n        self.helmet_model = load_model(\"helmet-nonhelmet_cnn.h5\")\\n\\n        self.root = tk.Tk()\\n        self.root.title(\"Helmet Detection\")\\n\\n        self.label = tk.Label(self.root)\\n        self.label.pack()\\n\\n        # Folder to save snapshots\\n        self.output_folder = \"C:\\\\Users\\\\Asus\\\\Videos\\\\Captures\\\\New folder\"\\n\\n        self.bike_detected = {}  # Dictionary to track detected bikes\\n\\n        self.update()\\n\\n        self.root.mainloop()\\n\\n    def update(self):\\n        ret, frame = self.cap.read()\\n\\n        if ret:\\n            # Resize frame for speedup\\n            frame = cv2.resize(frame, (self.frame_width, self.frame_height))\\n            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\\n\\n            # YOLOv3 detection\\n            blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\\n            self.net.setInput(blob)\\n            outs = self.net.forward(self.net.getUnconnectedOutLayersNames())\\n\\n            helmet_detected = False  # Flag to check if a helmet is detected\\n\\n            for out in outs:\\n                for detection in out:\\n                    scores = detection[5:]\\n                    class_id = np.argmax(scores)\\n                    confidence = scores[class_id]\\n                    if confidence > 0.5 and class_id == 0:  # Class ID for helmet (adjust if needed)\\n                        x, y, w, h = self.get_bbox_coordinates(detection)\\n\\n                        # Check if width and height are positive\\n                        if w > 0 and h > 0:\\n                            # Extract helmet region from the frame\\n                            helmet_roi = frame[y:y + h, x:x + w]\\n\\n                            # Check if the helmet_roi is not empty\\n                            if not helmet_roi.size == 0:\\n                                # Preprocess helmet_roi for helmet-nonhelmet model\\n                                helmet_roi_resized = cv2.resize(helmet_roi, (224, 224))\\n                                helmet_roi_normalized = helmet_roi_resized / 255.0\\n                                helmet_roi_final = np.expand_dims(helmet_roi_normalized, axis=0)\\n\\n                                # Predict helmet or nonhelmet\\n                                prediction = self.helmet_model.predict(helmet_roi_final)[0]\\n\\n                                # Draw bounding box and label\\n                                label = \"Helmet\" if prediction[0] > 0.5 else \"No Helmet\"\\n                                color = (0, 255, 0) if label == \"Helmet\" else (0, 0, 255)\\n                                cv2.rectangle(frame_rgb, (x, y), (x + w, y + h), color, 2)\\n                                cv2.putText(frame_rgb, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\\n\\n                                helmet_detected = True\\n\\n                                # Store the image if a bike is detected without a helmet and it\\'s not already stored\\n                                if label == \"No Helmet\" and self.bike_detected.get(label) is None:\\n                                    cv2.imwrite(\\n                                        f\"{self.output_folder}/bike_no_helmet_{int(self.cap.get(cv2.CAP_PROP_POS_FRAMES))}.png\",\\n                                        frame)\\n                                    self.bike_detected[label] = True\\n\\n            # Reset the dictionary if no helmet is detected\\n            if not helmet_detected:\\n                self.bike_detected = {}\\n\\n            # Convert the frame to a format compatible with Tkinter\\n            image = Image.fromarray(frame_rgb)\\n            image = ImageTk.PhotoImage(image=image)\\n\\n            # Update the label with the new image\\n            self.label.config(image=image)\\n            self.label.image = image\\n\\n        # Schedule the next update after 10 milliseconds\\n        self.root.after(10, self.update)\\n\\n    def get_bbox_coordinates(self, detection):\\n        center_x, center_y, w, h = int(detection[0] * self.frame_width), int(detection[1] * self.frame_height),                                    int(detection[2] * self.frame_width), int(detection[3] * self.frame_height)\\n        x, y = int(center_x - w / 2), int(center_y - h / 2)\\n        return x, y, w, h\\n\\nif __name__ == \"__main__\":\\n    app = HelmetDetectionApp(video_source=\"video.mp4\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "class HelmetDetectionApp:\n",
    "    def __init__(self, video_source):\n",
    "        self.video_source = video_source\n",
    "        self.cap = cv2.VideoCapture(self.video_source)\n",
    "\n",
    "        self.frame_width = 500\n",
    "        self.frame_height = 500\n",
    "\n",
    "        # Load YOLOv3\n",
    "        self.net = cv2.dnn.readNet(\"yolov3-custom.cfg\", \"yolov3-custom_7000.weights\")\n",
    "\n",
    "        # Load helmet-nonhelmet model\n",
    "        self.helmet_model = load_model(\"helmet-nonhelmet_cnn.h5\")\n",
    "\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Helmet Detection\")\n",
    "\n",
    "        self.label = tk.Label(self.root)\n",
    "        self.label.pack()\n",
    "\n",
    "        # Folder to save snapshots\n",
    "        self.output_folder = \"C:\\\\Users\\\\Asus\\\\Videos\\\\Captures\\\\New folder\"\n",
    "\n",
    "        self.bike_detected = {}  # Dictionary to track detected bikes\n",
    "\n",
    "        self.update()\n",
    "\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def update(self):\n",
    "        ret, frame = self.cap.read()\n",
    "\n",
    "        if ret:\n",
    "            # Resize frame for speedup\n",
    "            frame = cv2.resize(frame, (self.frame_width, self.frame_height))\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # YOLOv3 detection\n",
    "            blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "            self.net.setInput(blob)\n",
    "            outs = self.net.forward(self.net.getUnconnectedOutLayersNames())\n",
    "\n",
    "            helmet_detected = False  # Flag to check if a helmet is detected\n",
    "\n",
    "            for out in outs:\n",
    "                for detection in out:\n",
    "                    scores = detection[5:]\n",
    "                    class_id = np.argmax(scores)\n",
    "                    confidence = scores[class_id]\n",
    "                    if confidence > 0.5 and class_id == 0:  # Class ID for helmet (adjust if needed)\n",
    "                        x, y, w, h = self.get_bbox_coordinates(detection)\n",
    "\n",
    "                        # Check if width and height are positive\n",
    "                        if w > 0 and h > 0:\n",
    "                            # Extract helmet region from the frame\n",
    "                            helmet_roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "                            # Check if the helmet_roi is not empty\n",
    "                            if not helmet_roi.size == 0:\n",
    "                                # Preprocess helmet_roi for helmet-nonhelmet model\n",
    "                                helmet_roi_resized = cv2.resize(helmet_roi, (224, 224))\n",
    "                                helmet_roi_normalized = helmet_roi_resized / 255.0\n",
    "                                helmet_roi_final = np.expand_dims(helmet_roi_normalized, axis=0)\n",
    "\n",
    "                                # Predict helmet or nonhelmet\n",
    "                                prediction = self.helmet_model.predict(helmet_roi_final)[0]\n",
    "\n",
    "                                # Draw bounding box and label\n",
    "                                label = \"Helmet\" if prediction[0] > 0.5 else \"No Helmet\"\n",
    "                                color = (0, 255, 0) if label == \"Helmet\" else (0, 0, 255)\n",
    "                                cv2.rectangle(frame_rgb, (x, y), (x + w, y + h), color, 2)\n",
    "                                cv2.putText(frame_rgb, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "                                helmet_detected = True\n",
    "\n",
    "                                # Store the image if a bike is detected without a helmet and it's not already stored\n",
    "                                if label == \"No Helmet\" and self.bike_detected.get(label) is None:\n",
    "                                    cv2.imwrite(\n",
    "                                        f\"{self.output_folder}/bike_no_helmet_{int(self.cap.get(cv2.CAP_PROP_POS_FRAMES))}.png\",\n",
    "                                        frame)\n",
    "                                    self.bike_detected[label] = True\n",
    "\n",
    "            # Reset the dictionary if no helmet is detected\n",
    "            if not helmet_detected:\n",
    "                self.bike_detected = {}\n",
    "\n",
    "            # Convert the frame to a format compatible with Tkinter\n",
    "            image = Image.fromarray(frame_rgb)\n",
    "            image = ImageTk.PhotoImage(image=image)\n",
    "\n",
    "            # Update the label with the new image\n",
    "            self.label.config(image=image)\n",
    "            self.label.image = image\n",
    "\n",
    "        # Schedule the next update after 10 milliseconds\n",
    "        self.root.after(10, self.update)\n",
    "\n",
    "    def get_bbox_coordinates(self, detection):\n",
    "        center_x, center_y, w, h = int(detection[0] * self.frame_width), int(detection[1] * self.frame_height), \\\n",
    "                                   int(detection[2] * self.frame_width), int(detection[3] * self.frame_height)\n",
    "        x, y = int(center_x - w / 2), int(center_y - h / 2)\n",
    "        return x, y, w, h\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = HelmetDetectionApp(video_source=\"video.mp4\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import cv2\\nimport numpy as np\\nfrom keras.models import load_model\\nimport tkinter as tk\\nfrom PIL import Image, ImageTk\\n\\nclass HelmetDetectionApp:\\n    \"\"\"Application for detecting helmets in a video stream.\"\"\"\\n    HELMET_CLASS_ID = 0  # Update with the correct class ID for helmets\\n\\n    def __init__(self, video_source):\\n        self.video_source = video_source\\n        self.cap = cv2.VideoCapture(self.video_source)\\n\\n        self.frame_width = 500\\n        self.frame_height = 500\\n\\n        # Load YOLOv3\\n        self.net = cv2.dnn.readNet(\"yolov3-custom.cfg\", \"yolov3-custom_7000.weights\")\\n\\n        # Load helmet-nonhelmet model\\n        self.helmet_model = load_model(\"helmet-nonhelmet_cnn.h5\")\\n\\n        self.root = tk.Tk()\\n        self.root.title(\"Helmet Detection\")\\n\\n        self.label = tk.Label(self.root)\\n        self.label.pack()\\n\\n        # Folder to save snapshots\\n        self.output_folder = \"C:\\\\Users\\\\Asus\\\\Videos\\\\Captures\\\\New folder\"\\n\\n        self.bike_detected = {}  # Dictionary to track detected bikes\\n\\n        self.update()\\n\\n        self.root.mainloop()\\n\\n    def update(self):\\n        ret, frame = self.cap.read()\\n\\n        if ret:\\n            frame_rgb = self.process_frame(frame)\\n\\n            # Convert the frame to a format compatible with Tkinter\\n            image = Image.fromarray(frame_rgb)\\n            image = ImageTk.PhotoImage(image=image)\\n\\n            # Update the label with the new image\\n            self.label.config(image=image)\\n            self.label.image = image\\n\\n        # Schedule the next update after 10 milliseconds\\n        self.root.after(10, self.update)\\n\\n    def process_frame(self, frame):\\n        # Initialize j\\n        j = 0\\n\\n        # Resize frame for speedup\\n        frame = cv2.resize(frame, (self.frame_width, self.frame_height))\\n        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\\n\\n        # YOLOv3 detection\\n        blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\\n        self.net.setInput(blob)\\n        outs = self.net.forward(self.net.getUnconnectedOutLayersNames())\\n\\n        helmet_detected = False  # Flag to check if a helmet is detected\\n\\n        for out in outs:\\n            for detection in out:\\n                scores = detection[5:]\\n                class_id = np.argmax(scores)\\n                confidence = scores[class_id]\\n                if confidence > 0.5 and class_id == self.HELMET_CLASS_ID:\\n                    x, y, w, h = self.get_bbox_coordinates(detection)\\n\\n                    # Check if width and height are positive\\n                    if w > 0 and h > 0:\\n                        helmet_roi = self.extract_helmet_roi(frame, x, y, w, h)\\n\\n                        # Check if the helmet_roi is not empty\\n                        if not helmet_roi.size == 0:\\n                            prediction = self.predict_helmet_nonhelmet(helmet_roi)\\n\\n                            label = \"Helmet\" if prediction[0] > 0.5 else \"No Helmet\"\\n                            color = (0, 255, 0) if label == \"Helmet\" else (0, 0, 255)\\n                            cv2.rectangle(frame_rgb, (x, y), (x + w, y + h), color, 2)\\n                            cv2.putText(frame_rgb, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\\n\\n                            helmet_detected = True\\n\\n                            # Store the image if a bike is detected without a helmet and it\\'s not already stored\\n                            if label == \"No Helmet\" and self.bike_detected.get(label) is None:\\n                                # Save the image using your provided code\\n                                name = self.video_source.split(\"\\\\\")[-1].split(\".\")[0]  # Extract video name\\n                                j += 1\\n                                cv2.imwrite(f\"{self.output_folder}/{name}_{str(j)}.jpg\", frame)\\n\\n        # ... (your existing code)\\n\\n        return frame_rgb\\n\\n    def get_bbox_coordinates(self, detection):\\n        center_x, center_y, w, h = int(detection[0] * self.frame_width), int(detection[1] * self.frame_height),                                    int(detection[2] * self.frame_width), int(detection[3] * self.frame_height)\\n        x, y = int(center_x - w / 2), int(center_y - h / 2)\\n        return x, y, w, h\\n\\n    def extract_helmet_roi(self, frame, x, y, w, h):\\n        return frame[y:y + h, x:x + w]\\n\\n    def predict_helmet_nonhelmet(self, helmet_roi):\\n        # Preprocess helmet_roi for helmet-nonhelmet model\\n        helmet_roi_resized = cv2.resize(helmet_roi, (224, 224))\\n        helmet_roi_normalized = helmet_roi_resized / 255.0\\n        helmet_roi_final = np.expand_dims(helmet_roi_normalized, axis=0)\\n\\n        # Predict helmet or nonhelmet\\n        prediction = self.helmet_model.predict(helmet_roi_final)[0]\\n        return prediction\\n\\nif __name__ == \"__main__\":\\n    app = HelmetDetectionApp(video_source=\"video.mp4\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "class HelmetDetectionApp:\n",
    "    \"\"\"Application for detecting helmets in a video stream.\"\"\"\n",
    "    HELMET_CLASS_ID = 0  # Update with the correct class ID for helmets\n",
    "\n",
    "    def __init__(self, video_source):\n",
    "        self.video_source = video_source\n",
    "        self.cap = cv2.VideoCapture(self.video_source)\n",
    "\n",
    "        self.frame_width = 500\n",
    "        self.frame_height = 500\n",
    "\n",
    "        # Load YOLOv3\n",
    "        self.net = cv2.dnn.readNet(\"yolov3-custom.cfg\", \"yolov3-custom_7000.weights\")\n",
    "\n",
    "        # Load helmet-nonhelmet model\n",
    "        self.helmet_model = load_model(\"helmet-nonhelmet_cnn.h5\")\n",
    "\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Helmet Detection\")\n",
    "\n",
    "        self.label = tk.Label(self.root)\n",
    "        self.label.pack()\n",
    "\n",
    "        # Folder to save snapshots\n",
    "        self.output_folder = \"C:\\\\Users\\\\Asus\\\\Videos\\\\Captures\\\\New folder\"\n",
    "\n",
    "        self.bike_detected = {}  # Dictionary to track detected bikes\n",
    "\n",
    "        self.update()\n",
    "\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def update(self):\n",
    "        ret, frame = self.cap.read()\n",
    "\n",
    "        if ret:\n",
    "            frame_rgb = self.process_frame(frame)\n",
    "\n",
    "            # Convert the frame to a format compatible with Tkinter\n",
    "            image = Image.fromarray(frame_rgb)\n",
    "            image = ImageTk.PhotoImage(image=image)\n",
    "\n",
    "            # Update the label with the new image\n",
    "            self.label.config(image=image)\n",
    "            self.label.image = image\n",
    "\n",
    "        # Schedule the next update after 10 milliseconds\n",
    "        self.root.after(10, self.update)\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        # Initialize j\n",
    "        j = 0\n",
    "\n",
    "        # Resize frame for speedup\n",
    "        frame = cv2.resize(frame, (self.frame_width, self.frame_height))\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # YOLOv3 detection\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        self.net.setInput(blob)\n",
    "        outs = self.net.forward(self.net.getUnconnectedOutLayersNames())\n",
    "\n",
    "        helmet_detected = False  # Flag to check if a helmet is detected\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5 and class_id == self.HELMET_CLASS_ID:\n",
    "                    x, y, w, h = self.get_bbox_coordinates(detection)\n",
    "\n",
    "                    # Check if width and height are positive\n",
    "                    if w > 0 and h > 0:\n",
    "                        helmet_roi = self.extract_helmet_roi(frame, x, y, w, h)\n",
    "\n",
    "                        # Check if the helmet_roi is not empty\n",
    "                        if not helmet_roi.size == 0:\n",
    "                            prediction = self.predict_helmet_nonhelmet(helmet_roi)\n",
    "\n",
    "                            label = \"Helmet\" if prediction[0] > 0.5 else \"No Helmet\"\n",
    "                            color = (0, 255, 0) if label == \"Helmet\" else (0, 0, 255)\n",
    "                            cv2.rectangle(frame_rgb, (x, y), (x + w, y + h), color, 2)\n",
    "                            cv2.putText(frame_rgb, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "                            helmet_detected = True\n",
    "\n",
    "                            # Store the image if a bike is detected without a helmet and it's not already stored\n",
    "                            if label == \"No Helmet\" and self.bike_detected.get(label) is None:\n",
    "                                # Save the image using your provided code\n",
    "                                name = self.video_source.split(\"\\\\\")[-1].split(\".\")[0]  # Extract video name\n",
    "                                j += 1\n",
    "                                cv2.imwrite(f\"{self.output_folder}/{name}_{str(j)}.jpg\", frame)\n",
    "\n",
    "        # ... (your existing code)\n",
    "\n",
    "        return frame_rgb\n",
    "\n",
    "    def get_bbox_coordinates(self, detection):\n",
    "        center_x, center_y, w, h = int(detection[0] * self.frame_width), int(detection[1] * self.frame_height), \\\n",
    "                                   int(detection[2] * self.frame_width), int(detection[3] * self.frame_height)\n",
    "        x, y = int(center_x - w / 2), int(center_y - h / 2)\n",
    "        return x, y, w, h\n",
    "\n",
    "    def extract_helmet_roi(self, frame, x, y, w, h):\n",
    "        return frame[y:y + h, x:x + w]\n",
    "\n",
    "    def predict_helmet_nonhelmet(self, helmet_roi):\n",
    "        # Preprocess helmet_roi for helmet-nonhelmet model\n",
    "        helmet_roi_resized = cv2.resize(helmet_roi, (224, 224))\n",
    "        helmet_roi_normalized = helmet_roi_resized / 255.0\n",
    "        helmet_roi_final = np.expand_dims(helmet_roi_normalized, axis=0)\n",
    "\n",
    "        # Predict helmet or nonhelmet\n",
    "        prediction = self.helmet_model.predict(helmet_roi_final)[0]\n",
    "        return prediction\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = HelmetDetectionApp(video_source=\"video.mp4\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 413ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_0.jpg\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Saving image to: C:\\Users\\Asus\\Videos\\Captures\\New folder/no_helmet_1.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "class HelmetDetectionApp:\n",
    "    def __init__(self, video_source, output_video_path):\n",
    "        self.video_source = video_source\n",
    "        self.cap = cv2.VideoCapture(self.video_source)\n",
    "\n",
    "        self.frame_width = 500\n",
    "        self.frame_height = 500\n",
    "\n",
    "        # Load helmet-nonhelmet model\n",
    "        self.helmet_model = load_model(\"helmet-nonhelmet_cnn.h5\")\n",
    "\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Helmet Detection\")\n",
    "\n",
    "        self.label = tk.Label(self.root)\n",
    "        self.label.pack()\n",
    "\n",
    "        # Folder to save snapshots\n",
    "        self.output_folder = r\"C:\\Users\\Asus\\Videos\\Captures\\New folder\"\n",
    "\n",
    "        # Video writer for saving processed video\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "        self.output_video = cv2.VideoWriter(output_video_path, fourcc, 20.0, (self.frame_width, self.frame_height))\n",
    "\n",
    "        self.bike_detected = {}  # Dictionary to track detected bikes\n",
    "\n",
    "        self.update()\n",
    "\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def update(self):\n",
    "        ret, frame = self.cap.read()\n",
    "\n",
    "        if ret:\n",
    "            frame_rgb = self.process_frame(frame)\n",
    "\n",
    "            # Convert the frame to a format compatible with Tkinter\n",
    "            image = Image.fromarray(frame_rgb)\n",
    "            image = ImageTk.PhotoImage(image=image)\n",
    "\n",
    "            # Update the label with the new image\n",
    "            self.label.config(image=image)\n",
    "            self.label.image = image\n",
    "\n",
    "            # Write the frame to the output video\n",
    "            self.output_video.write(frame_rgb)\n",
    "\n",
    "        else:\n",
    "            # Release the video writer when the video ends\n",
    "            self.output_video.release()\n",
    "\n",
    "        # Schedule the next update after 10 milliseconds\n",
    "        self.root.after(10, self.update)\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "    # Resize frame for speedup\n",
    "        frame = cv2.resize(frame, (self.frame_width, self.frame_height))\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Preprocess frame for helmet-nonhelmet model\n",
    "        frame_resized = cv2.resize(frame_rgb, (224, 224))\n",
    "        frame_normalized = frame_resized / 255.0\n",
    "        frame_final = np.expand_dims(frame_normalized, axis=0)\n",
    "\n",
    "    # Predict helmet or nonhelmet\n",
    "        prediction = self.helmet_model.predict(frame_final)[0]\n",
    "\n",
    "    # Draw a bounding box based on the model prediction\n",
    "        label = \"Helmet\" if prediction > 0.5 else \"No Helmet\"\n",
    "        color = (0, 255, 0) if label == \"Helmet\" else (0, 0, 255)\n",
    "        cv2.rectangle(frame_rgb, (0, 0), (self.frame_width, self.frame_height), color, 2)\n",
    "        cv2.putText(frame_rgb, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "    # Store the image if a bike is detected without a helmet\n",
    "        if label == \"No Helmet\":\n",
    "        # Save the image with a unique filename\n",
    "            output_path = f\"{self.output_folder}/no_helmet_{len(self.bike_detected)}.jpg\"\n",
    "            print(f\"Saving image to: {output_path}\")\n",
    "            cv2.imwrite(output_path, frame)\n",
    "            self.bike_detected[label] = True\n",
    "    \n",
    "        return frame_rgb\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        return frame_rgb\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = HelmetDetectionApp(video_source=\"video.mp4\", output_video_path=\"processed_video.avi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
